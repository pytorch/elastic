#!/usr/bin/env python3

# Copyright (c) Facebook, Inc. and its affiliates.
# All rights reserved.
#
# This source code is licensed under the BSD-style license found in the
# LICENSE file in the root directory of this source tree.

import abc


class State(abc.ABC):
    """
    Simple class that maintains the state of a trainer / tester.

    Initializer simply assigns provided stateful objects to the
    associated member functions. There are a few helper functions for
    dealing with the member objects.
    """

    @abc.abstractmethod
    def __init__(self):
        pass

    @abc.abstractmethod
    def should_save_checkpoint(self, rank):
        """
        - Application need decide when to save checkpoint.
        eg: take checkpoint every x samples trained or every x seconds.

        - Every trainer need to return the same result.
        In DDP, backward pass call all_reduce to collect all gradient,
        this reqiures all trainers to anticipate. It might timeout if a trainer
        is stop and doing checkpoint while other worker complete the gradient
        computing. To prevent this, we put a barrier at the managed training loop
        while doing checkpoint, to make all trainers stop and waiting checkpoint
        complete.
        """
        pass

    @abc.abstractmethod
    def deep_copy(self):
        """
        Duplicate the State object

        TODO(T47593024): rename/rethink deep_copy/rollback methods as we want
        to get the minimal state snapshot to be able to recreate it. One
        extreme example is to use serialize/deserialize to do snapshot/rollback
        as well.
        """

        pass

    def supports_rollback(self):
        """
        Whether the PET training loop should deep copy state on each iteration
        in case an error occurs.
        Default is True, which leads to more correct behavior, but
        copying state can be very expensive for some models and dataloaders.
        If False, then `state` is assumed to be valid even if an error occurs
        during a train step.
        """

        return True

    def rollback(self, state):
        """
        rollback to the input copy of the state, returns the new state object
        that is rewound to the input state.

        TODO: implementation needs to re-evaluated based on where we want to
        take deep_copy (and potentially serialize/deserialize methods).
        """

        return state

    @abc.abstractmethod
    def sync(self, world_size, rank):
        """
        Figure out the latest state in the process group and
        broadcast it to all the workers.

        e.g., state could keep the which samples in the dataset have already been
              trained from on each worker. After state.sync(), it will know all the
              samples trained alreadys in the whole process group.

        Returns the latest state
        """

        pass

    @abc.abstractmethod
    def serialize(self, stream):
        """
        Serialize the state object to a stream
        """

        pass

    @abc.abstractmethod
    def deserialize(self, stream):
        """
        From a stream generated by state.serialize(), reconstruct a State Object
        """

        pass
